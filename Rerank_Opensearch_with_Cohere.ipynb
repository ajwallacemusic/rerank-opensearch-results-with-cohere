{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking Opensearch Results with Cohere\n",
        "This is the example companion notebook to the blog post Reranking Opensearch Results with Cohere. Here we provide all of the code and test data to try out Cohere's reranking api integrated in Opensearch.\n",
        "\n",
        "The only thing you need to run the code is a Cohere api key, which you will be prompted for when running the notebook."
      ],
      "metadata": {
        "id": "G9FZYH1TBiBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "7UUzdWBXChJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "# wget will download opensearch, opensearch-py is the python client for opensearch, and beir will be where we retrieve our test data\n",
        "!pip install wget opensearch-py beir"
      ],
      "metadata": {
        "id": "RVRE6Er8A4T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q-JtZodQ_wsB"
      },
      "outputs": [],
      "source": [
        "# download opensearch 2.12 and adjust some settings\n",
        "\n",
        "!wget https://artifacts.opensearch.org/releases/bundle/opensearch/2.12.0/opensearch-2.12.0-linux-x64.tar.gz\n",
        "!tar -xvf opensearch-2.12.0-linux-x64.tar.gz\n",
        "\n",
        "!sudo swapoff -a\n",
        "\n",
        "with open('/etc/sysctl.conf', 'a') as writefile:\n",
        "    writefile.write(\"vm.max_map_count=262144\\n\")\n",
        "    writefile.write(\"plugins.security.disabled: true\\n\")\n",
        "\n",
        "with open('/etc/sysctl.conf', 'r') as readfile:\n",
        "    print(readfile.read())\n",
        "\n",
        "with open('./opensearch-2.12.0/config/opensearch.yml', 'a') as writefile:\n",
        "    writefile.write(\"plugins.security.disabled: true\\n\")\n",
        "\n",
        "with open('./opensearch-2.12.0/config/opensearch.yml', 'r') as readfile:\n",
        "    print(readfile.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qURlcd1A-nE"
      },
      "outputs": [],
      "source": [
        "# setup local perms to run opensearch\n",
        "\n",
        "!sudo chown -R daemon:daemon opensearch-2.12.0/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axBiBd35BGK6"
      },
      "outputs": [],
      "source": [
        "# start opensearch\n",
        "\n",
        "%%bash --bg\n",
        "sudo -H -u daemon opensearch-2.12.0/bin/opensearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vWkJfJQBI9S"
      },
      "outputs": [],
      "source": [
        "# give opensearch time to start\n",
        "\n",
        "!sleep 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFlf-uzWBKfl"
      },
      "outputs": [],
      "source": [
        "# check opensearch connection\n",
        "\n",
        "!curl -X GET http://localhost:9200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from opensearchpy import OpenSearch\n",
        "\n",
        "# create opensearch client\n",
        "\n",
        "host = 'localhost'\n",
        "port = 9200\n",
        "\n",
        "# Create the client with ssl and auth disabled, NOT to be used for production!\n",
        "client = OpenSearch(\n",
        "    hosts = [{'host': host, 'port': port}],\n",
        "    http_compress = True, # enables gzip compression for request bodies\n",
        "    use_ssl = False,\n",
        "    verify_certs = False,\n",
        "    ssl_assert_hostname = False,\n",
        "    ssl_show_warn = False,\n",
        "    timeout=500\n",
        ")\n",
        "\n",
        "print(client.info())"
      ],
      "metadata": {
        "id": "Be6Mm5G7b93_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# getpass allows you to input your api key without printing it for the world to see.\n",
        "cohere_api_key = getpass(\"paste your cohere api key here\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vh2Rzg7qCl_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register a Cohere Rerank Model"
      ],
      "metadata": {
        "id": "LdvI1txlDN5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an ML Connector"
      ],
      "metadata": {
        "id": "Rr7stqiCDUm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGtsMeioAr86"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:9200/_plugins/_ml/connectors/_create\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "data = {\n",
        "    \"name\": \"cohere-rerank\",\n",
        "    \"description\": \"The connector to Cohere reanker model\",\n",
        "    \"version\": \"1\",\n",
        "    \"protocol\": \"http\",\n",
        "    \"credential\": {\n",
        "        \"cohere_key\": cohere_api_key\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"model\": \"rerank-english-v2.0\"\n",
        "    },\n",
        "    \"actions\": [\n",
        "        {\n",
        "            \"action_type\": \"predict\",\n",
        "            \"method\": \"POST\",\n",
        "            \"url\": \"https://api.cohere.ai/v1/rerank\",\n",
        "            \"headers\": {\n",
        "                \"Authorization\": \"Bearer ${credential.cohere_key}\"\n",
        "            },\n",
        "            \"request_body\": \"{ \\\"documents\\\": ${parameters.documents}, \\\"query\\\": \\\"${parameters.query}\\\", \\\"model\\\": \\\"${parameters.model}\\\", \\\"top_n\\\": ${parameters.top_n} }\",\n",
        "            \"pre_process_function\": \"connector.pre_process.cohere.rerank\",\n",
        "            \"post_process_function\": \"connector.post_process.cohere.rerank\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(response)\n",
        "print(response.json())\n",
        "connector_id = response.json()['connector_id']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register and Deploy the Model"
      ],
      "metadata": {
        "id": "NMD_r6w4DZo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://localhost:9200/_plugins/_ml/models/_register?deploy=true\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "data = {\n",
        "    \"name\": \"cohere rerank model\",\n",
        "    \"function_name\": \"remote\",\n",
        "    \"description\": \"test rerank model\",\n",
        "    \"connector_id\": connector_id\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json())\n",
        "task_id = response.json()['task_id']\n",
        "model_id = response.json()['model_id']"
      ],
      "metadata": {
        "id": "mqqGl2ecZCKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Model"
      ],
      "metadata": {
        "id": "nGPcETgnDgyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "url = \"http://localhost:9200/_plugins/_ml/models/hB9kkZIBrwGp_yq1pS5O/_predict\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "data = {\n",
        "  \"parameters\": {\n",
        "    \"query\": \"Who is the main character of Star Wars?\",\n",
        "    \"documents\": [\n",
        "      \"Jar-Jar Binks is a comical, possibly secret sith character in Star Wars.\",\n",
        "      \"Darth Vader, aka Anakin Skywalker is the main antagonist of the original Star Wars trilogy.\",\n",
        "      \"Luke Skywalker is the main protagonist of the original Star Wars trilogy.\",\n",
        "      \"Emperor Palpatine is arguably the main antogonist as he is the main sith lord.\"\n",
        "    ],\n",
        "    \"top_n\": 4\n",
        "  }\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(json.dumps(response.json()[\"inference_results\"], indent=4))"
      ],
      "metadata": {
        "id": "d-13gsU6ZOnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure a Reranking (Search) Pipeline"
      ],
      "metadata": {
        "id": "UvCsQIMPDmss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://localhost:9200/_search/pipeline/rerank_pipeline_cohere\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "data = {\n",
        "    \"description\": \"Pipeline for reranking with Cohere Rerank model\",\n",
        "    \"response_processors\": [\n",
        "        {\n",
        "            \"rerank\": {\n",
        "                \"ml_opensearch\": {\n",
        "                    \"model_id\": model_id\n",
        "                },\n",
        "                \"context\": {\n",
        "                    \"document_fields\": [\"title\", \"txt\"],\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.put(url, headers=headers, json=data)\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "ArFM2Akeb21u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Index Test Data\n",
        "We're using the scifact dataset from the BEIR project."
      ],
      "metadata": {
        "id": "E_MRVDzrDsbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from typing import List, Dict\n",
        "from opensearchpy.helpers import bulk\n",
        "from beir import util\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "\n",
        "\n",
        "dataset = \"scifact\"\n",
        "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
        "out_dir = \"datasets\"\n",
        "data_path = util.download_and_unzip(url, out_dir)\n",
        "corpus, _, _ = GenericDataLoader(data_path).load(split=\"test\")\n",
        "\n",
        "hostname = \"localhost:9200\"\n",
        "index_name = \"scifact\"\n",
        "\n",
        "# define a function that will index the docs from the dataset corpus\n",
        "def index_corpus(\n",
        "    corpus: Dict[str, Dict[str, str]],\n",
        "    index_name: str,\n",
        "    es_client: OpenSearch,\n",
        "):\n",
        "    \"\"\"\n",
        "    Pushing documents over to our index\n",
        "\n",
        "    Args:\n",
        "        `corpus`: The corpus of the dataset we have selected. It's a Huggingface dataset with the three fields (`_id`, `title`, `text`)\n",
        "        `index_name`: The name of the Elasticsearch index\n",
        "        `es_client`: An instance of a Python Elasticsearch client\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    def get_iterable():\n",
        "        for _id, value in corpus.items():\n",
        "          doc = {\n",
        "              \"_id\": str(_id),\n",
        "              \"_op_type\": \"index\",\n",
        "              \"refresh\": \"wait_for\",\n",
        "              \"title\": value[\"title\"],\n",
        "              \"txt\": value[\"text\"],\n",
        "          }\n",
        "          yield doc\n",
        "\n",
        "    # and bulk index them\n",
        "    bulk(client=es_client, index=index_name, actions=get_iterable(), max_retries=3)\n",
        "\n",
        "    # making sure that the index has been refreshed\n",
        "    es_client.indices.refresh(index=index_name)\n",
        "\n",
        "# index the docs\n",
        "index_corpus(corpus, index_name, client)"
      ],
      "metadata": {
        "id": "j7H6Bot8cYsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to use in printing search results\n",
        "def format_response(response):\n",
        "  hits = []\n",
        "\n",
        "  for hit in response[\"hits\"][\"hits\"]:\n",
        "      response_object = {\n",
        "          \"id\": hit['_id'],\n",
        "          \"score\": hit['_score'],\n",
        "          \"title\": hit['_source']['title'],\n",
        "          \"text\": format(hit['_source']['txt'])\n",
        "      }\n",
        "      hits.append(response_object)\n",
        "\n",
        "  print(json.dumps(hits, indent=2))"
      ],
      "metadata": {
        "id": "r3aHH8ZuEtGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Opensearch"
      ],
      "metadata": {
        "id": "Puu3ERikE5Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Establish Baseline BM25\n",
        "First we'll create a basic multi_match query that will score the documents with BM25."
      ],
      "metadata": {
        "id": "6X5jhIXwFQkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = 'A total of 1,000 people in the UK are asymptomatic carriers of vCJD infection.'"
      ],
      "metadata": {
        "id": "Fjpo-TWeFXrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    index=\"scifact\",\n",
        "    body={\n",
        "    \"query\": {\n",
        "        \"multi_match\": {\n",
        "            \"query\": query_text,\n",
        "            \"type\": \"best_fields\",\n",
        "            \"fields\": [\n",
        "                \"title\",\n",
        "                \"txt\"\n",
        "            ],\n",
        "            \"tie_breaker\": 0.5\n",
        "        }\n",
        "    },\n",
        "    \"size\": 10\n",
        "}\n",
        ")\n",
        "\n",
        "format_response(res)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WCF-rmrfdN2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Rerank Search Pipeline\n",
        "Now we'll create a query using our rerank search pipeline."
      ],
      "metadata": {
        "id": "DFj6ScpSFVlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    index=\"scifact\",\n",
        "    search_pipeline=\"rerank_pipeline_cohere\",\n",
        "    body={\n",
        "    \"query\": {\n",
        "        \"multi_match\": {\n",
        "            \"query\": query_text,\n",
        "            \"type\": \"best_fields\",\n",
        "            \"fields\": [\n",
        "                \"title\",\n",
        "                \"txt\"\n",
        "            ],\n",
        "            \"tie_breaker\": 0.5\n",
        "        }\n",
        "    },\n",
        "    \"size\": 10,\n",
        "    \"ext\": {\n",
        "        \"rerank\": {\n",
        "            \"query_context\": {\n",
        "                \"query_text\": query_text\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        ")\n",
        "\n",
        "format_response(res)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S-XI6Tn3bafm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Results\n",
        "Our very scientific example query comes directly from the scifi dataset: “A total of 1,000 people in the UK are asymptomatic carriers of vCJD infection.” The expected result is the document with id “13734012” and title “Prevalent abnormal prion protein in human appendixes after bovine spongiform encephalopathy epizootic: large scale survey”.\n",
        "\n",
        "We can see this document was ranked second in our normal search and first in our reranked results. While this is a nice anecdotal demonstration of the improved relevance, we calculated several relevance metrics for all of the queries in the scifi dataset, which demonstrates a consistent improvement in all scores as seen below.\n"
      ],
      "metadata": {
        "id": "YGTaPm68Fp-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Metrics\n",
        "__Relevance (Normalized Discounted Cumulative Gain)__\n",
        "\n",
        "|          | SBERT   | TAS-B   | BM25 + CE | BM25    | BM25 + Cohere |\n",
        "|----------|---------|---------|-----------|---------|---------------|\n",
        "| NDCG@1   | 0.42333 | 0.44667 |    0.5733 | 0.57667 |       0.62667 |\n",
        "| NDCG@3   | 0.48416 | 0.50432 |    0.6314 | 0.63658 |       0.69593 |\n",
        "| NDCG@5   | 0.48416 | 0.52853 |     0.652 | 0.66524 |        0.7141 |\n",
        "| NDCG@10  | 0.53789 | 0.55485 |     0.672 | 0.69064 |       0.73495 |\n",
        "| NDCG@100 | 0.57592 | 0.58717 |     0.678 | 0.71337 |       0.75241 |\n",
        "\n",
        "- SBERT refers to an exact k-nn match using the sbert msmarco-distilbert-base-v3 model.\n",
        "- TAS-B is exact match with sbert msmarco-distilbert-base-tas-b model.\n",
        "- BM25 + CE is the base bm25 results reranked with the ms-marco-electra-base SBERT cross-encoder.\n",
        "- BM25 is the base performance of a multi_match query in Opensearch.\n",
        "- Finally, BM25 + Cohere is the performance of Opensearch when using the Cohere rerank pipeline.\n",
        "\n",
        "__Latency__\n",
        "\n",
        "| Latency | BM25    | BM25 + Cohere | BM25 + CE CPU |\n",
        "|---------|---------|---------------|---------------|\n",
        "| Average | 14.26ms | 214.03ms      | 8745.06ms     |\n",
        "| P50     | 13.06ms | 150.35ms      | 8527.61ms     |\n",
        "| P90     | 19.73ms | 406.88ms      | 12713.91ms    |\n",
        "| P99     | 31.51ms | 870.71ms      | 15520.40ms    |"
      ],
      "metadata": {
        "id": "PTG2L5_jFzVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, relevance (as measured by nDCG is improved) at the cost of some latency (which makes sense because we’re reaching out across the internet to the cohere api for each request.) However, the Cohere reranking pipeline provides an advantage over self-hosting a cross-encoder pipeline, where performance degrades significantly without proper processing power. In our tests, we ran the sbert cross-encoder on google collab’s CPU and you can see the latency reached unacceptable levels. To improve the performance, the production environment would likely need many high performance CPUs or even GPUs would be preferred."
      ],
      "metadata": {
        "id": "5ZNMurMuGkvD"
      }
    }
  ]
}